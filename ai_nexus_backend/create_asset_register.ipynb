{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Automated Data Science Asset Register\n",
    "\n",
    "[Code adapted from https://github.com/moj-analytical-services/data-science-assets]\n",
    "\n",
    "This notebook uses the GitHub API to pull information from the repos in `assets.yaml`. \\\n",
    "The API call extracts the `yaml` block from each GitHub repo and uses this to populate a dataframe. \\\n",
    "The Gov Notify service is then used to send reminder emails for projects past their review date. \\\n",
    "The dataframe is formatted into html and saved. (ambition is to automate adding this to sharepoint, subject to permissions being granted)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T10:55:59.848923Z",
     "start_time": "2024-09-27T10:55:59.826399Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load packages\n",
    "from github import Github\n",
    "import yaml\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T10:56:01.013775Z",
     "start_time": "2024-09-27T10:56:01.009840Z"
    }
   },
   "outputs": [],
   "source": [
    "## Function takes markdown content (e.g. from a GitHub Readme) and returns the contents of the first yaml code block.\n",
    "\n",
    "def extract_yaml_from_md(md_content):\n",
    "    # Regular expression pattern to match the FIRST fenced YAML block\n",
    "    yaml_block_pattern = re.compile(r'```yaml(.*?)```', re.DOTALL)\n",
    "    \n",
    "    # Search for the first YAML block\n",
    "    match = yaml_block_pattern.search(md_content)\n",
    "    if match:\n",
    "        yaml_content = match.group(1).strip()  # Remove leading/trailing whitespace\n",
    "        try:\n",
    "            # Parse the first YAML content block\n",
    "            return yaml.safe_load(yaml_content)\n",
    "        except yaml.YAMLError as e:\n",
    "            print(\"Error parsing YAML content:\", e)\n",
    "            return None\n",
    "    else:\n",
    "        # Explicitly return None if no YAML blocks are found\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T10:58:15.880998Z",
     "start_time": "2024-09-27T10:58:15.814842Z"
    }
   },
   "outputs": [],
   "source": [
    "# read in api tokens\n",
    "\n",
    "import dotenv\n",
    "\n",
    "secrets = dotenv.dotenv_values(\"../.env\")\n",
    "user_agent = secrets[\"AGENT\"]\n",
    "pat = secrets[\"PAT\"] # TODO: Implement OAuth\n",
    "org_nm1 = secrets[\"ORG_NM1\"]\n",
    "org_nm2 = secrets[\"ORG_NM2\"]\n",
    "\n",
    "github_api_token = pat\n",
    "github_api_token\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Github scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T10:58:26.594526Z",
     "start_time": "2024-09-27T10:58:26.573622Z"
    }
   },
   "outputs": [],
   "source": [
    "g = Github(github_api_token)\n",
    "\n",
    "# Load in list of repos with assets and their organisation\n",
    "with open('../data/assets.yaml', 'r') as file:\n",
    "    data_list = yaml.safe_load(file)\n",
    "\n",
    "# Convert the list of dictionaries to a list of tuples\n",
    "repo_names = [(item['name'], item['organisation']) for item in data_list]\n",
    "\n",
    "print(repo_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the asset repositories and scrape info from Github \n",
    "\n",
    "table_data = []\n",
    "\n",
    "for repo_name, org_name in repo_names:\n",
    "    \n",
    "    org = g.get_organization(org_name)    \n",
    "    repo = org.get_repo(repo_name)\n",
    "    \n",
    "    # Get repo name and url and initialise data object for this repo\n",
    "    data = {\n",
    "        'Name': repo.name,\n",
    "        'Github': repo.html_url,\n",
    "    }\n",
    "    \n",
    "        # Get YAML contents from README (note Name (repo name) is overwritten by the name in the yaml if it exists)\n",
    "    try:\n",
    "        readme = repo.get_readme()\n",
    "        readme_content = readme.decoded_content.decode(\"utf-8\")\n",
    "        \n",
    "        # Extract yaml from the readme using function\n",
    "        data.update(extract_yaml_from_md(readme_content))\n",
    "        \n",
    "    except Exception as e: # This will happen if there's no readme or no yaml block\n",
    "        print(f\"Error retrieving YAML for {repo_name}: {e}\")\n",
    "\n",
    "    # Get the date of the last commit and append to data\n",
    "    try:\n",
    "        commits = repo.get_commits()\n",
    "        last_commit_date = commits[0].commit.committer.date\n",
    "        \n",
    "        # Convert the last commit date to a string format, e.g., YYYY-MM-DD\n",
    "        formatted_date = last_commit_date.strftime('%Y-%m-%d')\n",
    "\n",
    "        # Process the last commit date\n",
    "        data['Last Commit Date'] = formatted_date\n",
    "        \n",
    "        print(f\"The last commit date for {repo_name} is: {last_commit_date}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving commits for {repo_name}: {e}\")\n",
    "    \n",
    "    print(data)\n",
    "    table_data.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dictionary keys all lower case\n",
    "table_data = [{k.lower() : v for k,v in item.items()} for item in table_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dictionary data to a pandas df \n",
    "df = pd.DataFrame(table_data)\n",
    "\n",
    "# Get next review data as datetime\n",
    "df['review_date'] = pd.to_datetime(df['next review date'], format='%b-%y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df.columns) != 17:\n",
    "    print(\"WARNING: Unexpected or missing columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename and re-order columns for final output table\n",
    "new_columns = {\n",
    "             'name': 'Name',\n",
    "             'category' : 'Category', \n",
    "             'description' : 'Description',\n",
    "             'impact' : 'Impact',\n",
    "             'g6 lead' : 'G6 lead', \n",
    "             'sro' : 'SRO',\n",
    "             'technical lead' : 'Technical lead', \n",
    "             'business lead' : 'Business lead', \n",
    "             'last review date' : 'Last review date',\n",
    "             'next review date' : 'Next review date', \n",
    "             'outage impact' : 'Outage impact', \n",
    "             'maintenance (fte)': 'Maintenance (FTE)',\n",
    "             'documentation' : 'Documentation', \n",
    "             'github' : 'Github', \n",
    "             'last commit date' : 'Last Commit Date'\n",
    "    \n",
    "}\n",
    "\n",
    "# Set the DataFrame to the new order and rename\n",
    "df = df[list(new_columns.keys())].rename(columns=new_columns)\n",
    "\n",
    "\n",
    "# # Add hyperlinks\n",
    "# df['Github'] = df['Github'].apply(lambda x: f'<a href=\"{x}\">Repo</a>')\n",
    "# df['Documentation'] = df['Documentation'].apply(lambda x: f'<a href=\"{x}\">Link</a>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI Nexus",
   "language": "python",
   "name": "venv_ai_nexus"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
